{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\viral\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reviews():\n",
    "    raw = requests.get(\"https://raw.githubusercontent.com/patelviralb/text-summarization/main/dataset/cornell_reviews.json\").text.strip()\n",
    "    corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_input_corpus(documents):\n",
    "    documents = []\n",
    "    classes = []\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    for entry in corpus:\n",
    "        documents.append(entry['text'])\n",
    "        classes.append(entry['class'])\n",
    "\n",
    "    vectorizer = CountVectorizer(input=documents, max_df=0.25, token_pattern=r'\\b[a-zA-Z0-9]*[a-zA-Z][a-zA-Z0-9]*\\b', ngram_range=(1,3), max_features=300000, binary=True)\n",
    "    count_vector = vectorizer.fit_transform(documents)\n",
    "\n",
    "    vectors = count_vector.toarray()\n",
    "#     vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#     return vectors, classes, vocab\n",
    "    return vectors, documents, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_test_train_corpus(vectors, documents, classes):\n",
    "    document_indices = [*range(0, len(documents), 1)]\n",
    "    test_train_data_indces = train_test_split(document_indices, train_size = 0.75, random_state = 41)\n",
    "    # print(\"len(test_train_data_indces):\\t{}\".format(len(test_train_data_indces)))\n",
    "    # print(\"len(test_train_data_indces[0]):\\t{}\".format(len(test_train_data_indces[0])))\n",
    "    # print(\"len(test_train_data_indces[1]):\\t{}\".format(len(test_train_data_indces[1])))\n",
    "\n",
    "    train_vectors = []\n",
    "    train_documents = []\n",
    "    train_classes = []\n",
    "\n",
    "    for index in test_train_data_indces[0]:\n",
    "        train_vectors.append(vectors[index])\n",
    "        train_documents.append(documents[index])\n",
    "        train_classes.append(classes[index])\n",
    "\n",
    "    test_vectors = []\n",
    "    test_documents = []\n",
    "    test_classes = []\n",
    "\n",
    "    for index in test_train_data_indces[1]:\n",
    "        test_vectors.append(vectors[index])\n",
    "        test_documents.append(documents[index])\n",
    "        test_classes.append(classes[index])\n",
    "\n",
    "    # print(\"len(train_vectors):\\t{}\".format(len(train_vectors)))\n",
    "    # print(\"len(train_documents):\\t{}\".format(len(train_documents)))\n",
    "    # print(\"len(train_classes):\\t{}\".format(len(train_classes)))\n",
    "\n",
    "    # print(\"len(test_vectors):\\t{}\".format(len(test_vectors)))\n",
    "    # print(\"len(test_documents):\\t{}\".format(len(test_documents)))\n",
    "    # print(\"len(test_classes):\\t{}\".format(len(test_classes)))\n",
    "    \n",
    "    return train_vectors, train_documents, train_classes, test_vectors, test_documents, test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(train_vectors, train_classes):\n",
    "    logistic_regression_model = LogisticRegression(C=0.05, solver='liblinear', max_iter = 500, penalty=\"l2\")\n",
    "    logistic_regression_model.fit(train_vectors, train_classes)\n",
    "    \n",
    "    return logistic_regression_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(model, test_vectors, test_classes):\n",
    "    accuracy = accuracy_score(test_classes, model.predict(test_vectors))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Accuracy Computation\n",
    "\n",
    "Below code computes the baseline accuracy after dividing the corpus into training and test dataset. This accuracy will be used to compare with the accuracies generated after summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_reviews()\n",
    "vectors, documents, classes = vectorize_input_corpus(corpus)\n",
    "\n",
    "# print(\"type(vectors):\\t{}\".format(type(vectors)))\n",
    "# print(\"type(documents):\\t{}\".format(type(documents)))\n",
    "# print(\"type(classes):\\t{}\".format(type(classes)))\n",
    "\n",
    "# print(\"len(vectors):\\t{}\".format(len(vectors)))\n",
    "# print(\"len(documents):\\t{}\".format(len(documents)))\n",
    "# print(\"len(classes):\\t{}\".format(len(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, train_documents, train_classes, test_vectors, test_documents, test_classes = distribute_test_train_corpus(vectors, documents, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_accuracy:\t0.896\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = get_model(train_vectors, train_classes)\n",
    "baseline_accuracy = run_evaluation(logistic_regression_model, test_vectors, test_classes)\n",
    "\n",
    "print(\"baseline_accuracy:\\t{}\".format(baseline_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Text using Weighted Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(document):\n",
    "    original_text = document\n",
    "    # Preprocessing\n",
    "    formatted_text = re.sub(r'\\s+', ' ',  re.sub('[^a-zA-Z]', ' ', document))\n",
    "    # Converting Text To Sentences\n",
    "    sentence_list = sent_tokenize(document)\n",
    "    \n",
    "#     print(\"original_text:\\n{}\".format(original_text))\n",
    "#     print(\"formatted_text:\\n{}\".format(formatted_text))\n",
    "#     print(\"sentence_list:\\n{}\".format(sentence_list))\n",
    "    \n",
    "    # Find Weighted Frequency of Occurrence\n",
    "    stop_words = stopwords.words('english')\n",
    "    word_frequencies = {}\n",
    "    for word in word_tokenize(formatted_text):\n",
    "        if word not in stop_words:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "#     print(\"word_frequencies:\\n{}\".format(word_frequencies))\n",
    "    \n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    \n",
    "#     print(\"word_frequencies:\\n{}\".format(word_frequencies))\n",
    "    \n",
    "    # Calculating Sentence Scores\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentence_list:\n",
    "        if len(sentence.split(' ')) < 1000:\n",
    "            for word in word_tokenize(sentence.lower()):\n",
    "                if word in word_frequencies.keys():\n",
    "                    if sentence not in sentence_scores.keys():\n",
    "                        sentence_scores[sentence] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sentence] += word_frequencies[word]\n",
    "    \n",
    "#     print(\"len(sentence_scores):\\n{}\".format(len(sentence_scores)))\n",
    "#     print(\"sentence_scores:\\n{}\".format(sentence_scores))\n",
    "    \n",
    "    # Getting the Summary\n",
    "    summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "#     print(\"summary_sentences:\\n{}\".format(summary_sentences))\n",
    "#     print(\"summary:\\n{}\".format(summary))\n",
    "    \n",
    "    return summary, len(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_sentence_count):\t1500\n",
      "min(train_sentence_count):\t1\n",
      "argmin(train_sentence_count):\t655\n",
      "max(train_sentence_count):\t188\n",
      "argmax(train_sentence_count):\t289\n",
      "--------------------------------------------------\n",
      "MIN train_documents[655]:\n",
      "this film is extraordinarily horrendous and i'm not going to waste any more words on it . \n",
      "MIN train_summary[655]:\n",
      "this film is extraordinarily horrendous and i'm not going to waste any more words on it .\n",
      "**************************************************\n",
      "len(test_sentence_count):\t500\n",
      "min(test_sentence_count):\t5\n",
      "argmin(test_sentence_count):\t247\n",
      "max(test_sentence_count):\t172\n",
      "argmax(test_sentence_count):\t88\n",
      "--------------------------------------------------\n",
      "MIN test_documents[247]:\n",
      "deserves recognition for : making this relatively youthful critic feel extremely old and crotchety20 capsule review : this is what feel-good family entertainment has morphed into in the 90's : an hour-and-a-half commercial , disguised as an unnecessary remake , in which the defining image is that of a grown man launching a volume of green protoplasmic goo out of his ass . ( between this , rocketman , and george of the jungle , disney has recently eclipsed longtime champion troma as the studio most likely to include a fart joke in a film . ) as the absent-minded professor who invents the titular computer-generated goop , a listless robin williams manages the difficult task of making original lead fred macmurray seem sprightly . the only thing that made this film borderline tolerable for me is my newly-founded but firm belief that writer/producer john hughes is going to spend his eternal afterlife being conked in the noggin by all of the different blunt instruments he's used for comedic effect in films like this and the odious home alone series . take your kids to see boogie nights instead . \n",
      "MIN test_summary[247]:\n",
      "deserves recognition for : making this relatively youthful critic feel extremely old and crotchety20 capsule review : this is what feel-good family entertainment has morphed into in the 90's : an hour-and-a-half commercial , disguised as an unnecessary remake , in which the defining image is that of a grown man launching a volume of green protoplasmic goo out of his ass . the only thing that made this film borderline tolerable for me is my newly-founded but firm belief that writer/producer john hughes is going to spend his eternal afterlife being conked in the noggin by all of the different blunt instruments he's used for comedic effect in films like this and the odious home alone series . as the absent-minded professor who invents the titular computer-generated goop , a listless robin williams manages the difficult task of making original lead fred macmurray seem sprightly . ( between this , rocketman , and george of the jungle , disney has recently eclipsed longtime champion troma as the studio most likely to include a fart joke in a film . ) take your kids to see boogie nights instead .\n"
     ]
    }
   ],
   "source": [
    "train_summary = []\n",
    "train_sentence_count = []\n",
    "for index, document in enumerate(train_documents):\n",
    "    summary, sentence_count = get_summary(document)\n",
    "    train_summary.append(summary)\n",
    "    train_sentence_count.append(sentence_count)\n",
    "\n",
    "print(\"len(train_sentence_count):\\t{}\".format(len(train_sentence_count)))\n",
    "print(\"min(train_sentence_count):\\t{}\".format(min(train_sentence_count)))\n",
    "print(\"argmin(train_sentence_count):\\t{}\".format(np.argmin(train_sentence_count)))\n",
    "print(\"max(train_sentence_count):\\t{}\".format(max(train_sentence_count)))\n",
    "print(\"argmax(train_sentence_count):\\t{}\".format(np.argmax(train_sentence_count)))\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"MIN train_documents[655]:\\n{}\".format(train_documents[655]))\n",
    "print(\"MIN train_summary[655]:\\n{}\".format(train_summary[655]))\n",
    "print(\"*\"*50)\n",
    "# print(\"len(train_summary):\\n{}\".format(len(train_summary)))\n",
    "# print(\"train_summary:\\n{}\".format(train_summary))\n",
    "\n",
    "test_summary = []\n",
    "test_sentence_count = []\n",
    "for index, document in enumerate(test_documents):\n",
    "    summary, sentence_count = get_summary(document)\n",
    "    test_summary.append(summary)\n",
    "    test_sentence_count.append(sentence_count)\n",
    "\n",
    "print(\"len(test_sentence_count):\\t{}\".format(len(test_sentence_count)))\n",
    "print(\"min(test_sentence_count):\\t{}\".format(min(test_sentence_count)))\n",
    "print(\"argmin(test_sentence_count):\\t{}\".format(np.argmin(test_sentence_count)))\n",
    "print(\"max(test_sentence_count):\\t{}\".format(max(test_sentence_count)))\n",
    "print(\"argmax(test_sentence_count):\\t{}\".format(np.argmax(test_sentence_count)))\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"MIN test_documents[247]:\\n{}\".format(test_documents[247]))\n",
    "print(\"MIN test_summary[247]:\\n{}\".format(test_summary[247]))\n",
    "\n",
    "# print(\"len(test_summary):\\n{}\".format(len(test_summary)))\n",
    "# print(\"test_summary:\\n{}\".format(test_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_summary(summary_corpus):\n",
    "    vectorizer = CountVectorizer(input=summary_corpus, max_df=0.25, token_pattern=r'\\b[a-zA-Z0-9]*[a-zA-Z][a-zA-Z0-9]*\\b', ngram_range=(1,3), max_features=300000, binary=True)\n",
    "    count_vector = vectorizer.fit_transform(summary_corpus)\n",
    "\n",
    "    summary_vectors = count_vector.toarray()\n",
    "    \n",
    "    return summary_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_average_summary_accuracy:\t0.742\n"
     ]
    }
   ],
   "source": [
    "# < 30 words in sentence, 7 top sentences\n",
    "summary_corpus = []\n",
    "summary_corpus.extend(train_summary)\n",
    "summary_corpus.extend(test_summary)\n",
    "\n",
    "summary_vectors = vectorize_summary(summary_corpus)\n",
    "train_summary_vectors = summary_vectors[0:1500]\n",
    "test_summary_vectors = summary_vectors[1500:]\n",
    "\n",
    "logistic_regression_model_after_summary = get_model(train_summary_vectors, train_classes)\n",
    "weighted_average_summary_accuracy = run_evaluation(logistic_regression_model_after_summary, test_summary_vectors, test_classes)\n",
    "\n",
    "print(\"weighted_average_summary_accuracy:\\t{}\".format(weighted_average_summary_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_average_summary_accuracy:\t0.762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.762"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# < 1000 words in sentence, 7 top sentences\n",
    "summary_corpus = []\n",
    "summary_corpus.extend(train_summary)\n",
    "summary_corpus.extend(test_summary)\n",
    "\n",
    "summary_vectors = vectorize_summary(summary_corpus)\n",
    "train_summary_vectors = summary_vectors[0:1500]\n",
    "test_summary_vectors = summary_vectors[1500:]\n",
    "\n",
    "logistic_regression_model_after_summary = get_model(train_summary_vectors, train_classes)\n",
    "weighted_average_summary_accuracy = run_evaluation(logistic_regression_model_after_summary, test_summary_vectors, test_classes)\n",
    "\n",
    "print(\"weighted_average_summary_accuracy:\\t{}\".format(weighted_average_summary_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted_average_summary_accuracy:\t0.784\n"
     ]
    }
   ],
   "source": [
    "# < 1000 words in sentence, 10 top sentences\n",
    "summary_corpus = []\n",
    "summary_corpus.extend(train_summary)\n",
    "summary_corpus.extend(test_summary)\n",
    "\n",
    "summary_vectors = vectorize_summary(summary_corpus)\n",
    "train_summary_vectors = summary_vectors[0:1500]\n",
    "test_summary_vectors = summary_vectors[1500:]\n",
    "\n",
    "logistic_regression_model_after_summary = get_model(train_summary_vectors, train_classes)\n",
    "weighted_average_summary_accuracy = run_evaluation(logistic_regression_model_after_summary, test_summary_vectors, test_classes)\n",
    "\n",
    "print(\"weighted_average_summary_accuracy:\\t{}\".format(weighted_average_summary_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
